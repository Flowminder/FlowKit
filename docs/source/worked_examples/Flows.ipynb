{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Crisis Analysis\n",
    "\n",
    "## Flows Above Normal\n",
    "\n",
    "In this worked example we assume the role of an analyst working in the aftermath of a significant crisis in Nepal. Our aim is to use FlowKit to investigate which administrative regions people have been displaced from/to during the crisis, following the methodology used in [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4779046/).\n",
    "\n",
    "### Load FlowClient and connect to FlowAPI\n",
    "\n",
    "We start by importing FlowClient. We also import [geopandas](http://geopandas.org/) and [mapboxgl](https://mapbox-mapboxgl-jupyter.readthedocs-hosted.com/en/latest/), which we will use later to to visualise the data.\n",
    "\n",
    "Mapbox requires an [access token](https://www.mapbox.com/account/), which should be set as the environment variable `MAPBOX_ACCESS_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowclient\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import mapboxgl\n",
    "from mapboxgl.utils import create_color_stops\n",
    "\n",
    "mapbox_token = os.getenv(\"MAPBOX_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must next generate a FlowAPI access token using [FlowAuth](../../analyst/#flowauth), and paste the token here as `TOKEN`. Once we have a token, we can start a connection to the FlowAPI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = flowclient.connect(\n",
    "    url=os.getenv(\"FLOWAPI_URL\", \"http://localhost:9090\"), token=TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate origin-destination matrices\n",
    "\n",
    "To estimate abnormal population movements, we will calculate two origin-destination matrices (or flows): a \"normal\" flow before the crisis occurs, and a \"crisis\" flow comparing subscriber locations before and during the crisis.\n",
    "\n",
    "Calculating these two flows requires three reference home locations. In this example we will use modal locations for three periods:\n",
    "\n",
    "- A \"benchmark\" period before the crisis begins,\n",
    "- A \"comparison\" period shortly before the crisis,\n",
    "- A \"focal\" period immediately after the crisis begins.\n",
    "\n",
    "Here we assume that the crisis begins on 10th February 2016.\n",
    "\n",
    "We first call the `modal_location_from_dates` function three times to create Python dictionaries containing the parameters for the three modal location queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_specs = {\n",
    "    \"benchmark\": flowclient.modal_location_from_dates(\n",
    "        start_date=\"2016-01-01\",\n",
    "        end_date=\"2016-01-21\",\n",
    "        method=\"last\",\n",
    "        aggregation_unit=\"admin3\",\n",
    "    ),\n",
    "    \"comparison\": flowclient.modal_location_from_dates(\n",
    "        start_date=\"2016-01-21\",\n",
    "        end_date=\"2016-02-10\",\n",
    "        method=\"last\",\n",
    "        aggregation_unit=\"admin3\",\n",
    "    ),\n",
    "    \"focal\": flowclient.modal_location_from_dates(\n",
    "        start_date=\"2016-02-10\",\n",
    "        end_date=\"2016-02-28\",\n",
    "        method=\"last\",\n",
    "        aggregation_unit=\"admin3\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal location queries return subscriber-level results, which cannot be accessed directly through FlowAPI. We can create spatially-aggregated query specifications by passing each modal location query specification to the `spatial_aggregate` function, and pass these query specifications to the `run_query` function to start running them. This function will return a query ID for each spatially-aggregated modal location query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_ids = {\n",
    "    period: flowclient.run_query(\n",
    "        connection=conn,\n",
    "        query=flowclient.spatial_aggregate(locations=query_spec),\n",
    "    )\n",
    "    for period, query_spec in home_locations_specs.items()\n",
    "}\n",
    "home_locations_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass the modal location dictionaries as parameters to the `flows` function, to create specifications for the two flows queries, and set the resulting queries running as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_specs = {\n",
    "    \"normal\": flowclient.flows(\n",
    "        from_location=home_locations_specs[\"benchmark\"],\n",
    "        to_location=home_locations_specs[\"comparison\"],\n",
    "        aggregation_unit=\"admin3\",\n",
    "    ),\n",
    "    \"crisis\": flowclient.flows(\n",
    "        from_location=home_locations_specs[\"benchmark\"],\n",
    "        to_location=home_locations_specs[\"focal\"],\n",
    "        aggregation_unit=\"admin3\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ids = {\n",
    "    flow: flowclient.run_query(connection=conn, query=query_spec)\n",
    "    for flow, query_spec in flows_specs.items()\n",
    "}\n",
    "flows_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can periodically check the status of the queries using the `get_status` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowclient.get_status(connection=conn, query_id=flows_ids[\"crisis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the distributions of locations\n",
    "\n",
    "While the flows are calculating, we download the geography for the level 3 administrative regions as GeoJSON using the `get_geography` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download geography data as GeoJSON\n",
    "regions = flowclient.get_geography(connection=conn, aggregation_unit=\"admin3\")\n",
    "\n",
    "# Create a geopandas GeoDataFrame from the GeoJSON\n",
    "regions_geodataframe = gpd.GeoDataFrame.from_features(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `get_result` to get the results of the modal location queries as `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_results = {\n",
    "    period: flowclient.get_result(\n",
    "        connection=conn,\n",
    "        query=flowclient.spatial_aggregate(locations=query_spec),\n",
    "    )\n",
    "    for period, query_spec in home_locations_specs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine these results with the geography data, and use the `Mapbox GL` library to create a choropleth showing the distribution of modal locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_geodataframe = regions_geodataframe.drop(columns=\"centroid\")\n",
    "\n",
    "for period in home_locations_specs.keys():\n",
    "    home_locations_geodataframe = home_locations_geodataframe.join(\n",
    "        home_locations_results[period]\n",
    "        .set_index(\"pcod\")\n",
    "        .rename(columns={\"total\": f\"Total ({period} period)\"}),\n",
    "        on=\"admin3pcod\",\n",
    "        how=\"left\",\n",
    "    ).fillna(0)\n",
    "\n",
    "home_locations_geodataframe = home_locations_geodataframe.rename(\n",
    "    columns={\"admin3pcod\": \"P-code\", \"admin3name\": \"Name\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_to_show = \"benchmark\"  # \"comparison\" \"focal\"\n",
    "\n",
    "# Limit for the colour scale\n",
    "max_total = max(\n",
    "    [\n",
    "        home_locations_geodataframe[f\"Total ({period} period)\"].max()\n",
    "        for period in home_locations_specs.keys()\n",
    "    ]\n",
    ")\n",
    "\n",
    "modal_locations_viz = mapboxgl.ChoroplethViz(\n",
    "    home_locations_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"Total ({period_to_show} period)\",\n",
    "    color_stops=create_color_stops(\n",
    "        np.linspace(0, max_total, 9), colors=\"YlGn\"\n",
    "    ),\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "modal_locations_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate flows above normal\n",
    "\n",
    "Once the flows queries have finished running, we can obtain the results for the flows. We can either use the `get_result` function, as we did above for the modal locations, or we can call `get_result_by_query_id` and pass the query id for the flows query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_results = {\n",
    "    flow: flowclient.get_result_by_query_id(connection=conn, query_id=query_id)\n",
    "    for flow, query_id in flows_ids.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subtract the \"normal\" flow from the \"crisis\" flow to find the flows above normal during the crisis period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_above_normal = (\n",
    "    flows_results[\"crisis\"]\n",
    "    .set_index([\"pcod_from\", \"pcod_to\"])\n",
    "    .subtract(\n",
    "        flows_results[\"normal\"].set_index([\"pcod_from\", \"pcod_to\"]),\n",
    "        fill_value=0,\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now aggregate the flows above normal to the `\"pcod_to\"` or `\"pcod_from\"` regions, excluding flows where the origin and destination regions are the same, to get the inflows/outflows above normal, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflows_above_normal = (\n",
    "    flows_above_normal[\n",
    "        flows_above_normal[\"pcod_from\"] != flows_above_normal[\"pcod_to\"]\n",
    "    ]\n",
    "    .groupby(\"pcod_to\")\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "outflows_above_normal = (\n",
    "    flows_above_normal[\n",
    "        flows_above_normal[\"pcod_from\"] != flows_above_normal[\"pcod_to\"]\n",
    "    ]\n",
    "    .groupby(\"pcod_from\")\n",
    "    .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the modal locations, we can combine these results with the geography data to display the data on choropleth maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out_flows_geodataframe = (\n",
    "    regions_geodataframe.set_index(\"admin3pcod\")\n",
    "    .join(\n",
    "        [\n",
    "            inflows_above_normal.rename(\n",
    "                columns={\"count\": \"inflow above normal\"}\n",
    "            ),\n",
    "            outflows_above_normal.rename(\n",
    "                columns={\"count\": \"outflow above normal\"}\n",
    "            ),\n",
    "        ],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "in_out_flows_geodataframe = in_out_flows_geodataframe.drop(\n",
    "    columns=\"centroid\"\n",
    ").rename(columns={\"admin3pcod\": \"P-code\", \"admin3name\": \"Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_to_show = \"in\"  # \"out\"\n",
    "\n",
    "# Limit for the colour scale\n",
    "max_count = max(\n",
    "    [\n",
    "        in_out_flows_geodataframe[f\"{direction}flow above normal\"].abs().max()\n",
    "        for direction in [\"in\", \"out\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "flows_viz = mapboxgl.ChoroplethViz(\n",
    "    in_out_flows_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"{direction_to_show}flow above normal\",\n",
    "    color_stops=create_color_stops(\n",
    "        np.linspace(-max_count, max_count, 11), colors=\"PiYG\"\n",
    "    ),\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "flows_viz.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
