{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commuting Patterns\n",
    "\n",
    "In this worked example we demonstrate the use of FlowKit to investigate commuting patterns. We will use `meaningful_locations_aggregate` queries to calculate subscribers' home and work locations, following methods developed by [Isaacman et al.](https://doi.org/10.1007/978-3-642-21726-5_9) and [Zagatti et al.](https://doi.org/10.1016/j.deveng.2018.03.002).\n",
    "\n",
    "### Load FlowClient and connect to FlowAPI\n",
    "\n",
    "We start by importing FlowClient. We also import [geopandas](http://geopandas.org/) and [mapboxgl](https://mapbox-mapboxgl-jupyter.readthedocs-hosted.com/en/latest/), which we will use later to to visualise the data.\n",
    "\n",
    "Mapbox requires an [access token](https://www.mapbox.com/account/), which should be set as the environment variable `MAPBOX_ACCESS_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowclient\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import mapboxgl\n",
    "from mapboxgl.utils import create_color_stops\n",
    "\n",
    "mapbox_token = os.getenv(\"MAPBOX_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must next generate an API access token using [FlowAuth](../../analyst/#flowauth), and paste the token here as `TOKEN`. Once we have a token, we can start a connection to the FlowAPI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = flowclient.connect(url=\"http://localhost:9090\", token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meaningful locations queries\n",
    "\n",
    "We assign a day-of-week score of +1 to events which occur on weekdays (Monday-Friday), and a score of -1 to weekends (Saturday, Sunday). We assign an hour-of-day score of +1 to events during \"working hours\", which we define here as 08:00-17:00, and a score of -1 to evening hours 19:00-07:00. We then define two labels: we label locations with a positive hour-of-day score as `\"work\"`, and locations with a negative hour-of-day score as `\"home\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_day_of_week_scores = {\n",
    "    \"monday\": 1,\n",
    "    \"tuesday\": 1,\n",
    "    \"wednesday\": 1,\n",
    "    \"thursday\": 1,\n",
    "    \"friday\": 1,\n",
    "    \"saturday\": -1,\n",
    "    \"sunday\": -1,\n",
    "}\n",
    "\n",
    "tower_hour_of_day_scores = [\n",
    "    -1, -1, -1, -1, -1, -1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, -1, -1, -1, -1, -1\n",
    "]\n",
    "\n",
    "meaningful_locations_labels = {\n",
    "    \"home\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[[-1, 1], [-1, -1], [-1e-06, -1], [-1e-06, 1]]],\n",
    "    },\n",
    "    \"work\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[[0, 1], [0, -1], [1, -1], [1, 1]]],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our labels, we now pass these to the `meaningful_locations_aggregate` function to create parameter dictionaries for two meaningful locations queries: a \"home location\", which will count the number of subscribers with \"evening\" locations in each level 3 adminstrative region, and a \"work location\", which will instead count \"daytime\" locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_spec = flowclient.meaningful_locations_aggregate(\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2016-01-07\",\n",
    "    label=\"home\",\n",
    "    labels=meaningful_locations_labels,\n",
    "    tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "    tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "    aggregation_unit=\"admin3\",\n",
    ")\n",
    "work_locations_spec = flowclient.meaningful_locations_aggregate(\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2016-01-07\",\n",
    "    label=\"work\",\n",
    "    labels=meaningful_locations_labels,\n",
    "    tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "    tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "    aggregation_unit=\"admin3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass these parameters to the `get_result` function, to get the results of the queries as `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations = flowclient.get_result(\n",
    "    connection=conn, query=home_locations_spec\n",
    ")\n",
    "\n",
    "work_locations = flowclient.get_result(\n",
    "    connection=conn, query=work_locations_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the distributions of home/work locations\n",
    "\n",
    "We use the `get_geography` function to download the geography for the level 3 administrative regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download geography data as GeoJSON\n",
    "regions = flowclient.get_geography(connection=conn, aggregation_unit=\"admin3\")\n",
    "\n",
    "# Create a geopandas GeoDataFrame from the GeoJSON\n",
    "regions_geodataframe = gpd.GeoDataFrame.from_features(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the geography data with the results of our meaningful locations queries to create a choropleth map showing the distribution of home/work locations, using the `geoviews` library for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join location counts to geography data\n",
    "locations_geodataframe = (\n",
    "    regions_geodataframe.drop(columns=\"centroid\")\n",
    "    .join(\n",
    "        home_locations.drop(columns=\"label\").set_index(\"pcod\"),\n",
    "        on=\"admin3pcod\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        work_locations.drop(columns=\"label\").set_index(\"pcod\"),\n",
    "        on=\"admin3pcod\",\n",
    "        lsuffix=\"_home\",\n",
    "        rsuffix=\"_work\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Rename columns for map labels\n",
    "locations_geodataframe = locations_geodataframe.rename(\n",
    "    columns={\n",
    "        \"admin3pcod\": \"P-code\",\n",
    "        \"admin3name\": \"Name\",\n",
    "        \"total_home\": \"Total (home)\",\n",
    "        \"total_work\": \"Total (work)\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_show = \"home\"  # \"work\"\n",
    "\n",
    "# Limit for the colour scale\n",
    "max_total = max([home_locations[\"total\"].max(), work_locations[\"total\"].max()])\n",
    "locations_viz = mapboxgl.ChoroplethViz(\n",
    "    locations_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"Total ({locations_to_show})\",\n",
    "    color_stops=create_color_stops(\n",
    "        np.linspace(0, max_total, 9), colors=\"YlGn\"\n",
    "    ),\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "locations_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate commuter flows\n",
    "\n",
    "In addition to looking at the distributions of our two meaningful locations separately, we can calculate an origin-destination matrix between the two labels. We call the `meaningful_locations_between_label_od_matrix` function to create a query specification, and pass this to `get_result` to get the result of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix_spec = flowclient.meaningful_locations_between_label_od_matrix(\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2016-01-07\",\n",
    "    label_a=\"home\",\n",
    "    label_b=\"work\",\n",
    "    labels=meaningful_locations_labels,\n",
    "    tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "    tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "    aggregation_unit=\"admin3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix = flowclient.get_result(connection=conn, query=od_matrix_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the number of subscribers who commute into each region from a different region, we first calculate the number of subscribers in each region with both their home and work locations in the same region (which we call `commuters_within_region` here), and then subtract this from the total flows into each region.\n",
    "\n",
    "Similarly, we can subtract `commuters_within_region` from the total flows out of each region to calculate the number of people with home locations in each region who commute to other regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commuters_within_region = (\n",
    "    od_matrix[od_matrix.pcod_from == od_matrix.pcod_to]\n",
    "    .drop(columns=[\"label_from\", \"label_to\", \"pcod_from\"])\n",
    "    .set_index(\"pcod_to\")\n",
    ")\n",
    "\n",
    "commuters_into_region = (\n",
    "    od_matrix.groupby(\"pcod_to\")\n",
    "    .sum()\n",
    "    .subtract(commuters_within_region, fill_value=0)\n",
    ")\n",
    "commuters_out_from_region = (\n",
    "    od_matrix.groupby(\"pcod_from\")\n",
    "    .sum()\n",
    "    .subtract(commuters_within_region, fill_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the meaningful locations above, we can combine these commuter in/outflows with the geography data to visualise the results on a choropleth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join location counts to geography data\n",
    "commuters_geodataframe = (\n",
    "    regions_geodataframe.drop(columns=\"centroid\")\n",
    "    .join(commuters_into_region, on=\"admin3pcod\", how=\"left\")\n",
    "    .join(\n",
    "        commuters_out_from_region,\n",
    "        on=\"admin3pcod\",\n",
    "        lsuffix=\"_in\",\n",
    "        rsuffix=\"_out\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Rename columns for map labels\n",
    "commuters_geodataframe = commuters_geodataframe.rename(\n",
    "    columns={\n",
    "        \"admin3pcod\": \"P-code\",\n",
    "        \"admin3name\": \"Name\",\n",
    "        \"total_in\": \"Commuters in\",\n",
    "        \"total_out\": \"Commuters out\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_to_show = \"in\"  # \"out\"\n",
    "\n",
    "# Limit for the colour scale\n",
    "max_count = max(\n",
    "    [\n",
    "        commuters_into_region[\"total\"].abs().max(),\n",
    "        commuters_out_from_region[\"total\"].abs().max(),\n",
    "        1,\n",
    "    ]\n",
    ")\n",
    "\n",
    "commuters_viz = mapboxgl.ChoroplethViz(\n",
    "    commuters_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"Commuters {direction_to_show}\",\n",
    "    color_stops=create_color_stops(\n",
    "        np.linspace(-max_count, max_count, 11), colors=\"PiYG\"\n",
    "    ),\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "commuters_viz.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
