{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commuting Patterns\n",
    "\n",
    "## Using meaningful locations queries\n",
    "\n",
    "In this worked example we demonstrate the use of FlowKit to investigate commuting patterns. We will use `meaningful_locations_aggregate` queries to calculate subscribers' home and work locations, following methods developed by [Isaacman et al.](https://doi.org/10.1007/978-3-642-21726-5_9) and [Zagatti et al.](https://doi.org/10.1016/j.deveng.2018.03.002).\n",
    "\n",
    "The Jupyter notebook for this worked example can be downloaded [here](https://github.com/Flowminder/FlowKit/raw/master/docs/source/analyst/worked_examples/commuting-patterns.ipynb), or can be run using the [quick start setup](../../install.md#quickinstall).\n",
    "\n",
    "### Load FlowClient and connect to FlowAPI\n",
    "\n",
    "We start by importing FlowClient. We also import [geopandas](http://geopandas.org/) and [mapboxgl](https://mapbox-mapboxgl-jupyter.readthedocs-hosted.com/en/latest/), which we will use later to to visualise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowclient\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import mapboxgl\n",
    "from mapboxgl.utils import create_color_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must next [generate a FlowAPI access token](../index.md#flowauth) using FlowAuth. If you are running this notebook using the [quick start setup](../../install.md#quickinstall), generating a token requires the following steps:\n",
    "\n",
    "1. Visit the FlowAuth login page at [http://localhost:9091](http://localhost:9091/).\n",
    "2. Log in with username `TEST_USER` and password `DUMMY_PASSWORD`.\n",
    "3. Under \"My Servers\", select `TEST_SERVER`.\n",
    "4. Click the `+` button to create a new token.\n",
    "5. Give the new token a name, and click `SAVE`.\n",
    "6. Copy the token string using the `COPY` button.\n",
    "7. Paste the token in this notebook as `TOKEN`.\n",
    "\n",
    "The steps are the same in a production setup, but the FlowAuth URL, login details and server name will differ.\n",
    "\n",
    "Once we have a token, we can start a connection to the FlowAPI system. If you are connecting to FlowAPI over https (recommended) and the system administrator has provided you with an SSL certificate file, you should provide the path to this file as the `ssl_certificate` argument to`flowclient.connect()` (in this example, you can set the path in the environment variable `SSL_CERTIFICATE_FILE`). If you are connecting over http, this argument is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = flowclient.connect(\n",
    "    url=os.getenv(\"FLOWAPI_URL\", \"http://localhost:9090\"),\n",
    "    token=TOKEN,\n",
    "    ssl_certificate=os.getenv(\"SSL_CERTIFICATE_FILE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meaningful locations queries\n",
    "\n",
    "We assign a day-of-week score of +1 to events which occur on weekdays (Monday-Friday), and a score of -1 to weekends (Saturday, Sunday). We assign an hour-of-day score of +1 to events during \"working hours\", which we define here as 08:00-17:00, and a score of -1 to evening hours 19:00-07:00. We then define two labels: we label locations with a positive hour-of-day score as `\"work\"`, and locations with a negative hour-of-day score as `\"home\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_day_of_week_scores = {\n",
    "    \"monday\": 1,\n",
    "    \"tuesday\": 1,\n",
    "    \"wednesday\": 1,\n",
    "    \"thursday\": 1,\n",
    "    \"friday\": 1,\n",
    "    \"saturday\": -1,\n",
    "    \"sunday\": -1,\n",
    "}\n",
    "\n",
    "tower_hour_of_day_scores = [\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "]\n",
    "\n",
    "meaningful_locations_labels = {\n",
    "    \"home\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[[-1, 1], [-1, -1], [-1e-06, -1], [-1e-06, 1]]],\n",
    "    },\n",
    "    \"work\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[[0, 1], [0, -1], [1, -1], [1, 1]]],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our labels, we now pass these to the `meaningful_locations_aggregate` function to create parameter dictionaries for two meaningful locations queries: a \"home location\", which will count the number of subscribers with \"evening\" locations in each level 3 adminstrative region, and a \"work location\", which will instead count \"daytime\" locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations_spec = flowclient.aggregates.meaningful_locations_aggregate_spec(\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2016-01-08\",\n",
    "    label=\"home\",\n",
    "    labels=meaningful_locations_labels,\n",
    "    tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "    tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "    aggregation_unit=\"admin3\",\n",
    ")\n",
    "work_locations_spec = flowclient.aggregates.meaningful_locations_aggregate_spec(\n",
    "    start_date=\"2016-01-01\",\n",
    "    end_date=\"2016-01-08\",\n",
    "    label=\"work\",\n",
    "    labels=meaningful_locations_labels,\n",
    "    tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "    tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "    aggregation_unit=\"admin3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass these parameters to the `get_result` function, to get the results of the queries as `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_locations = flowclient.get_result(connection=conn, query_spec=home_locations_spec)\n",
    "\n",
    "work_locations = flowclient.get_result(connection=conn, query_spec=work_locations_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the distributions of home/work locations\n",
    "\n",
    "We use the `get_geography` function to download the geography for the level 3 administrative regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download geography data as GeoJSON\n",
    "regions = flowclient.get_geography(connection=conn, aggregation_unit=\"admin3\")\n",
    "\n",
    "# Create a geopandas GeoDataFrame from the GeoJSON\n",
    "regions_geodataframe = gpd.GeoDataFrame.from_features(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the geography data with the results of our meaningful locations queries to create a choropleth map showing the distribution of home/work locations, using the `geoviews` library for visualisation.\n",
    "\n",
    "**Note:** Mapbox requires an [access token](https://www.mapbox.com/account/), which should be set as the environment variable `MAPBOX_ACCESS_TOKEN`. Note that this is only required for producing the Mapbox visualisations, which is completely separate from FlowKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join location counts to geography data\n",
    "locations_geodataframe = (\n",
    "    regions_geodataframe.drop(columns=\"centroid\")\n",
    "    .join(\n",
    "        home_locations.drop(columns=\"label\").set_index(\"pcod\"),\n",
    "        on=\"pcod\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        work_locations.drop(columns=\"label\").set_index(\"pcod\"),\n",
    "        on=\"pcod\",\n",
    "        lsuffix=\"_home\",\n",
    "        rsuffix=\"_work\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(value={\"value_home\": 0, \"value_work\": 0})\n",
    ")\n",
    "\n",
    "# Rename columns for map labels\n",
    "locations_geodataframe = locations_geodataframe.rename(\n",
    "    columns={\n",
    "        \"pcod\": \"P-code\",\n",
    "        \"value_home\": \"Total (home)\",\n",
    "        \"value_work\": \"Total (work)\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_to_show = \"home\"  # \"work\"\n",
    "\n",
    "mapbox_token = os.environ[\"MAPBOX_ACCESS_TOKEN\"]\n",
    "\n",
    "# Colour scale for legend\n",
    "max_total = max([home_locations[\"value\"].max(), work_locations[\"value\"].max()])\n",
    "color_stops = create_color_stops(np.linspace(0, max_total, 9), colors=\"YlGn\")\n",
    "\n",
    "locations_viz = mapboxgl.ChoroplethViz(\n",
    "    locations_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"Total ({locations_to_show})\",\n",
    "    color_stops=color_stops,\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "locations_viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate commuter flows\n",
    "\n",
    "In addition to looking at the distributions of our two meaningful locations separately, we can calculate an origin-destination matrix between the two labels. We call the `meaningful_locations_between_label_od_matrix` function to create a query specification, and pass this to `get_result` to get the result of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix_spec = (\n",
    "    flowclient.aggregates.meaningful_locations_between_label_od_matrix_spec(\n",
    "        start_date=\"2016-01-01\",\n",
    "        end_date=\"2016-01-08\",\n",
    "        label_a=\"home\",\n",
    "        label_b=\"work\",\n",
    "        labels=meaningful_locations_labels,\n",
    "        tower_day_of_week_scores=tower_day_of_week_scores,\n",
    "        tower_hour_of_day_scores=tower_hour_of_day_scores,\n",
    "        aggregation_unit=\"admin3\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_matrix = flowclient.get_result(connection=conn, query_spec=od_matrix_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the number of subscribers who commute into each region from a different region, we first calculate the number of subscribers in each region with both their home and work locations in the same region (which we call `commuters_within_region` here), and then subtract this from the total flows into each region.\n",
    "\n",
    "Similarly, we can subtract `commuters_within_region` from the total flows out of each region to calculate the number of people with home locations in each region who commute to other regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commuters_within_region = (\n",
    "    od_matrix[od_matrix.pcod_from == od_matrix.pcod_to]\n",
    "    .drop(columns=[\"label_from\", \"label_to\", \"pcod_from\"])\n",
    "    .set_index(\"pcod_to\")\n",
    ")\n",
    "\n",
    "commuters_into_region = (\n",
    "    od_matrix.groupby(\"pcod_to\").sum().subtract(commuters_within_region, fill_value=0)\n",
    ")\n",
    "commuters_out_from_region = (\n",
    "    od_matrix.groupby(\"pcod_from\").sum().subtract(commuters_within_region, fill_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the meaningful locations above, we can combine these commuter in/outflows with the geography data to visualise the results on a choropleth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join location counts to geography data\n",
    "commuters_geodataframe = (\n",
    "    regions_geodataframe.drop(columns=\"centroid\")\n",
    "    .join(commuters_into_region, on=\"pcod\", how=\"left\")\n",
    "    .join(\n",
    "        commuters_out_from_region,\n",
    "        on=\"pcod\",\n",
    "        lsuffix=\"_in\",\n",
    "        rsuffix=\"_out\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .fillna(value={\"value_in\": 0, \"value_out\": 0})\n",
    ")\n",
    "\n",
    "# Rename columns for map labels\n",
    "commuters_geodataframe = commuters_geodataframe.rename(\n",
    "    columns={\n",
    "        \"pcod\": \"P-code\",\n",
    "        \"value_in\": \"Commuters in\",\n",
    "        \"value_out\": \"Commuters out\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_to_show = \"in\"  # \"out\"\n",
    "\n",
    "mapbox_token = os.environ[\"MAPBOX_ACCESS_TOKEN\"]\n",
    "\n",
    "# Colour scale for legend\n",
    "max_total = max(\n",
    "    [\n",
    "        commuters_into_region[\"value\"].max(),\n",
    "        commuters_out_from_region[\"value\"].max(),\n",
    "        1,\n",
    "    ]\n",
    ")\n",
    "color_stops = create_color_stops(np.linspace(0, max_total, 9), colors=\"YlGn\")\n",
    "\n",
    "commuters_viz = mapboxgl.ChoroplethViz(\n",
    "    commuters_geodataframe.__geo_interface__,\n",
    "    access_token=mapbox_token,\n",
    "    color_property=f\"Commuters {direction_to_show}\",\n",
    "    color_stops=color_stops,\n",
    "    opacity=0.8,\n",
    "    line_color=\"black\",\n",
    "    line_width=0.5,\n",
    "    legend_gradient=True,\n",
    "    legend_layout=\"horizontal\",\n",
    "    legend_text_numeric_precision=0,\n",
    "    below_layer=\"waterway-label\",\n",
    "    center=(84.1, 28.4),\n",
    "    zoom=5.5,\n",
    ")\n",
    "\n",
    "commuters_viz.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
